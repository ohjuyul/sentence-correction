# eval_ckpt.py
import os, warnings
os.environ["TOKENIZERS_PARALLELISM"] = "false"
warnings.filterwarnings("ignore", message=".*Length of IterableDataset.*")

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from transformers import T5TokenizerFast

from model3 import CorrectionModel
from data_txt_stream import GrammarCorrectionDataset

# ====== 경로/설정 (필요시만 수정) ======
ENCODER_NAME = "beomi/kcbert-base"
DECODER_SPM  = "../spm_out/tokenizer_32k.model"

KO_VAL  = "../ko.val.txt"
COR_VAL = "../correct.val.txt"
KO_TEST  = "../ko.test.txt"
COR_TEST = "../correct.test.txt"

CKPT_PATH = "./checkpoints/step_222828_best_val_loss.pt"  # ← 확인하려는 ckpt 경로
ENC_MAX_LEN = 300
DEC_MAX_LEN = 256
BATCH_SIZE  = 8
NUM_WORKERS = 0
PIN_MEMORY  = torch.cuda.is_available()
LABEL_SMOOTHING = 0.1
IGNORE_INDEX = -100


# ====== 유틸 ======
def ensure_special_tokens(tok: T5TokenizerFast) -> T5TokenizerFast:
    changed = False
    if tok.pad_token is None:
        tok.add_special_tokens({"pad_token": "<pad>"}); changed = True
    if getattr(tok, "bos_token", None) is None:
        tok.add_special_tokens({"bos_token": "<s>"}); changed = True
    if tok.eos_token is None:
        tok.add_special_tokens({"eos_token": "</s>"}); changed = True
    if changed:
        print("[Info] Added missing special tokens to decoder tokenizer.")
    return tok

def build_dec_tok(spm_path: str) -> T5TokenizerFast:
    tok = T5TokenizerFast(vocab_file=spm_path, extra_ids=0, legacy=False)
    return ensure_special_tokens(tok)

class LabelSmoothingCE(nn.Module):
    def __init__(self, smoothing: float, ignore_index: int = -100):
        super().__init__()
        self.smoothing = smoothing
        self.ignore_index = ignore_index
    def forward(self, logits, targets):
        B, T, V = logits.shape
        pad_mask = targets.eq(self.ignore_index)
        n_valid = (~pad_mask).sum().clamp_min(1)
        if self.smoothing > 0.0:
            log_probs = torch.log_softmax(logits, dim=-1)
            nll = -log_probs.gather(dim=-1, index=targets.masked_fill(pad_mask, 0).unsqueeze(-1)).squeeze(-1)
            nll = nll.masked_fill(pad_mask, 0.0).sum() / n_valid
            smooth = -log_probs.mean(dim=-1)
            smooth = smooth.masked_fill(pad_mask, 0.0).sum() / n_valid
            return (1 - self.smoothing) * nll + self.smoothing * smooth
        else:
            return nn.CrossEntropyLoss(ignore_index=self.ignore_index)(logits.view(B*T, V), targets.view(B*T))

def cer_one(ref: str, hyp: str) -> float:
    R, H = ref, hyp
    n, m = len(R), len(H)
    if n == 0: return float(m > 0)
    dp = [[0]*(m+1) for _ in range(n+1)]
    for i in range(n+1): dp[i][0] = i
    for j in range(m+1): dp[0][j] = j
    for i in range(1, n+1):
        ri = R[i-1]
        for j in range(1, m+1):
            hj = H[j-1]
            dp[i][j] = min(dp[i-1][j]+1, dp[i][j-1]+1, dp[i-1][j-1]+(ri!=hj))
    return dp[n][m] / max(1, n)

def _trim_to_eos(arr, eos_id, pad_id, replace_ignore_with_pad=True):
    if replace_ignore_with_pad:
        arr = [pad_id if int(t) == IGNORE_INDEX else int(t) for t in arr]
    else:
        arr = [int(t) for t in arr]
    if eos_id in arr:
        cut = arr.index(eos_id) + 1
        arr = arr[:cut]
    return arr

@torch.no_grad()
def evaluate(model: CorrectionModel, loader: DataLoader, device) -> dict:
    model.eval()
    criterion = LabelSmoothingCE(LABEL_SMOOTHING, ignore_index=IGNORE_INDEX)

    total_loss, total_tok, total_cor, total_cer, n_cer = 0.0, 0, 0, 0.0, 0
    dec_tok = model.dec_tok
    pad_id  = dec_tok.pad_token_id
    eos_id  = dec_tok.eos_token_id

    num_batches = 0
    for batch in loader:  # tqdm 생략(IterableDataset 경고 피함)
        batch = {k: v.to(device, non_blocking=True) for k, v in batch.items()}

        logits = model(
            input_ids=batch["input_ids"],
            attention_mask=batch["attention_mask"],
            decoder_input_ids=batch["decoder_input_ids"],
            decoder_attention_mask=batch["decoder_attention_mask"],
        )
        total_loss += criterion(logits, batch["labels"]).item()
        num_batches += 1

        preds = logits.argmax(-1)
        golds = batch["labels"]
        mask  = golds.ne(IGNORE_INDEX)
        total_tok += mask.sum().item()
        total_cor += (preds.eq(golds) & mask).sum().item()

        # CER (EOS 기준으로 자르고 디코드)
        B = preds.size(0)
        for b in range(B):
            pred_ids = _trim_to_eos(preds[b].tolist(), eos_id, pad_id, replace_ignore_with_pad=False)
            gold_ids = _trim_to_eos(golds[b].tolist(), eos_id, pad_id, replace_ignore_with_pad=True)
            hyp = dec_tok.decode(pred_ids, skip_special_tokens=True)
            ref = dec_tok.decode(gold_ids, skip_special_tokens=True)
            total_cer += cer_one(ref, hyp); n_cer += 1

    avg_loss = total_loss / max(1, num_batches)
    acc = total_cor / max(1, total_tok) if total_tok > 0 else 0.0
    cer = total_cer / max(1, n_cer) if n_cer > 0 else 0.0
    return {"loss": avg_loss, "acc": acc, "cer": cer}


def build_loader(ko, cor, dec_tok, enc_name, enc_max_len, dec_max_len) -> DataLoader:
    ds = GrammarCorrectionDataset(
        ko_file=ko, correct_file=cor,
        tokenizer_name=enc_name, max_length=enc_max_len, stride=0,
        limit=None, decoder_tokenizer=dec_tok,
        dec_max_length=dec_max_len, downsample_prob=1.0,
    )
    return DataLoader(
        ds, batch_size=BATCH_SIZE, shuffle=False,
        num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY
    )


def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"[Info] device: {device}")

    # 토크나이저 & 모델
    dec_tok = build_dec_tok(DECODER_SPM)
    model = CorrectionModel(
        encoder_name=ENCODER_NAME,
        num_decoder_layers=6,
        decoder_tokenizer=dec_tok,
    ).to(device)

    # 체크포인트 로드
    print(f"[Load] {CKPT_PATH}")
    state = torch.load(CKPT_PATH, map_location=device)
    model.load_state_dict(state, strict=True)
    model.eval()

    # 로더
    val_loader  = build_loader(KO_VAL,  COR_VAL,  dec_tok, ENCODER_NAME, ENC_MAX_LEN, DEC_MAX_LEN)
    test_loader = build_loader(KO_TEST, COR_TEST, dec_tok, ENCODER_NAME, ENC_MAX_LEN, DEC_MAX_LEN)

    # 평가
    val_metrics  = evaluate(model, val_loader,  device)
    test_metrics = evaluate(model, test_loader, device)

    print(f"[VAL ] loss {val_metrics['loss']:.4f} | acc {val_metrics['acc']*100:.2f}% | cer {val_metrics['cer']:.4f}")
    print(f"[TEST] loss {test_metrics['loss']:.4f} | acc {test_metrics['acc']*100:.2f}% | cer {test_metrics['cer']:.4f}")


if __name__ == "__main__":
    main()

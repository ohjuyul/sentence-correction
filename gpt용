    def forward(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask=None):
        # decoder_input_ids가 None이면 bos_token_id를 추가하는 작업
        if decoder_input_ids is None:
            decoder_input_ids = torch.cat([torch.full((input_ids.size(0), 1), self.config.bos_token_id, device=input_ids.device), input_ids[:, :-1]], dim=1)

        encoder_outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)
        memory = encoder_outputs.last_hidden_state

        decoder_outputs = self.decoder(
            input_ids=decoder_input_ids,
            attention_mask=decoder_attention_mask,
            encoder_hidden_states=memory,
            encoder_attention_mask=attention_mask,
        )
